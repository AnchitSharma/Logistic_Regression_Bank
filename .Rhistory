setwd("~/R_Workspace")
load("~/R_Workspace/.RData")
BlackScholes <- function(S, K, r, T, sig, type){
if(type == "C"){
d1 <- (log(S/K) + (r + sig^2/2)*T) / (sig*sqrt(T))
d2 <- d1 - sig*sqrt(T)
value <- S*pnorm(d1) - K*exp(-r*T)*pnorm(d2)
return(value)
}
if(type == "P"){
d1 <- (log(S/K) + (r + sig^2/2)*T) / (sig*sqrt(T))
d2 <- d1 - sig*sqrt(T)
value <- (K*exp(-r*T)*pnorm(-d2)  - S*pnorm(-d1))
return(value)
}
}
call <- BlackScholes(110, 100, 0.04, 1, 0.2, "C")
call
put <- BlackScholes(110, 100, 0.04, 1, 0.2, "P")
data <- Quandl("WIKI/AAPL.4")
install.packages("Quandl")
library(Quandl)
data <- Quandl("WIKI/AAPL.4")
data <- read.csv("AAPL.csv")
View(data)
remove.packages("Quandl")
# retrieve the first 50 rows
recent_rows = data[1:50, ]
# Use the arrange function in dplyr package to get old values at top.
library(dplyr)
install.packages("dplyr")
# Use the arrange function in dplyr package to get old values at top.
library(dplyr)
recent_data <- ?arrange()
recent_data <- arrange(recent_rows, -row_number())
View(recent_rows)
View(recent_data)
View(recent_rows)
View(recent_data)
recent_data$returns <- c('NA', round(diff(log(recent_data$Close)), 3))
# convert the column to numeric
recent_data$returns <- as.numeric(recent_data$returns)
View(recent_data)
recent_data$returns <- c('NA', round(diff(log(recent_data$Close)), 3))
# convert the column to numeric
recent_data$returns <- as.numeric(recent_data$returns)
# calculate the standard deviation of the log returns
standard_deviation <- sd(recent_data$returns, na.rm = True)
# calculate the standard deviation of the log returns
standard_deviation <- sd(recent_data$returns, na.rm = TRUE)
source("~/R_Workspace/BlackScholes_Impl.R", encoding = 'UTF-8', echo=TRUE)
help(diff)
help()
?diff
diff(1:10, 2)
1:10
diff(1:10, 2, 2)
x <- cumsum(1:10)
x
x <- cumsum(x)
x
diff(x, lag = 2)
diff(x, differences = 2)
?log
diff(1:10)
annual_sigma <- standard_deviation*sqrt(250)
sqrt(250)
# Load necessary packages
library(tidyverse)
install.packages("tidyverse")
# Load necessary packages
library(tidyverse)
library(PerformanceAnalytics)
install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
# Download market data from Yahoo Finance
stock_data <- getSymbols("CS", src = "yahoo",
from = "2007-01-01", to = "2015-12-31")
# Download market data from Yahoo Finance
stock_data <- getSymbols("CS", src = "yahoo",
from = "2007-01-01", to = "2015-12-31")
# Download market data from Yahoo Finance
stock_data <- read.csv("USOI.csv")
View(stock_data)
# Download EURIBOR rates from ECB
rates_data <- read_csv("euribor_rates.csv")
View(rates_data)
# Load quarterly balance sheet data from CSV
balancesheet_data <- read_csv("balancesheet.csv")
View(balancesheet_data)
View(stock_data)
View(stock_data)
# Compute stock return volatility
stock_vol <- volatility(stock_data, method="close")
library(dplyr)
market_data <- read.csv("USOI.csv")
market_data <- market_data %>%
select(Date, Close, Volume)
View(market_data)
# Step 2: Calculate Market Value of Equity (VE) and returns volatility
market_data$MarketCap <- market_data$Close * market_data$Volume
market_data$Returns <- dailyReturn(Cl(market_data$Close))
install.packages("quantmod")
library(quantmod)
market_data$Returns <- dailyReturn(Cl(market_data$Close))
market_data$Returns <- dailyReturn(Cl(market_data$Close))
Cl(market_data$Close)
market_data$Close
market_data$Returns <- dailyReturn(Cl(market_data$Close))
Cl(market_data$Close)
library(tidyquant)
install.packages("tidyquant")
library(dplyr)
library(dplyr)
library(tidyquant)
market_data <- read.csv("USOI.csv")
# Convert Date column to Date format
market_data$Date <- as.Date(market_data$Date)
# Download market data using tidyquant
market_data <- tq_get("UBSG.SW", from = min(market_data$Date), to = max(market_data$Date)) %>%
select(date, adjusted, volume) %>%
rename(Date = date, Close = adjusted, Volume = volume)
View(market_data)
# Step 2: Calculate Market Value of Equity (VE) and returns volatility
market_data$MarketCap <- market_data$Close * market_data$Volume
market_data$Returns <- dailyReturn(market_data$Close)
View(market_data)
market_data$Returns <- c(NA, diff(log(market_data$Close)))
View(market_data)
volatility <- sd(market_data$Returns, na.rm = TRUE)
# Step 3: Download balance sheet data
# Assuming you have a CSV file with balance sheet data
balance_sheet <- read.csv("balance_sheet.csv")
# Step 3: Download balance sheet data
# Assuming you have a CSV file with balance sheet data
balance_sheet <- read.csv("balancesheet.csv")
# Convert Date column to Date format
balance_sheet$Date <- as.Date(balance_sheet$Date)
View(balance_sheet)
# Convert Date column to Date format
balance_sheet$Date <- as.Date(balance_sheet$X)
colnames(balance_sheet)
# Extract relevant columns
balance_sheet <- balance_sheet %>%
select(Date, Total.Debt, Total.Assets)  # Assuming 'Debt' and 'Assets' are relevant columns
View(balance_sheet)
# Step 3: Download balance sheet data
# Assuming you have a CSV file with balance sheet data
balance_sheet <- read.csv("balancesheet.csv")
# Convert Date column to Date format
balance_sheet$Date <- as.Date(balance_sheet$X)
# Extract relevant columns
balance_sheet <- balance_sheet %>%
select(Date, Total.Debt, Total.Assets, ExchangeRate)  # Assuming 'Debt' and 'Assets' are relevant columns
# Correct values
balance_sheet$Debt <- balance_sheet$Total.Debt * balance_sheet$ExchangeRate
balance_sheet$Assets <- balance_sheet$Total.Assets * balance_sheet$ExchangeRate
View(balance_sheet)
# Step 5: Combine market and balance sheet data
merged_data <- merge(market_data, balance_sheet, by = "Date", all = TRUE)
View(merged_data)
?with
# For simplicity, let's assume a basic model using Market Value of Equity and Debt
merged_data$PD <- with(merged_data, pnorm(-log(Debt/MarketCap) + (0.5 * volatility^2),
mean = 0, sd = volatility))
# Print the resulting data
print(merged_data)
View(balance_sheet)
library(tidyverse)
# Download market data using tidyquant
market_data <- tq_get("UBSG.SW", from = min(market_data$Date), to = max(market_data$Date)) %>%
select(date, adjusted, volume) %>%
rename(Date = date, Close = adjusted, Volume = volume)
View(market_data)
tq_get("UBSG.SW", from = min(market_data$Date), to = max(market_data$Date))
stock_data <- read.csv("USOI.csv")
View(stock_data)
# Download EURIBOR rates from ECB
rates_data <- read_csv("euribor_rates.csv")
View(rates_data)
# Load quarterly balance sheet data from CSV
balancesheet_data <- read_csv("balancesheet.csv")
Cl(stock_data)
xp <- Cl(stock_data)
View(xp)
?Cl
View(stock_data)
stock_data <- read.csv("UBSG.SW.csv")
# Download EURIBOR rates from ECB
rates_data <- read_csv("euribor_rates.csv")
View(rates_data)
# Load quarterly balance sheet data from CSV
balancesheet_data <- read_csv("balancesheet.csv")
View(stock_data)
stock_data$shares.outstanding <- 3230000000
# Compute market value of equity
mv_equity <- Cl(stock_data) * stock_data$shares.outstanding
View(mv_equity)
# Compute stock return volatility
stock_vol <- volatility(stock_data, method="close")
library(tidyverse)
stock_data <- read.csv("UBSG.SW.csv")
# Download EURIBOR rates from ECB
rates_data <- read_csv("euribor_rates.csv")
# Load quarterly balance sheet data from CSV
balancesheet_data <- read_csv("balancesheet.csv")
stock_data$shares.outstanding <- 3230000000
# Compute market value of equity
mv_equity <- Cl(stock_data) * stock_data$shares.outstanding
# Compute stock return volatility
stock_vol <- volatility(stock_data, method="close")
?volatility
# Compute stock return volatility
stock_vol <- volatility(stock_data, calc="close")
View(stock_data)
# volatility <- sd(market_data$Returns, na.rm = TRUE)
daily_diff <- diff(log(Cl(stock_data)))
Cl(stock_data)
log(Cl(stock_data))
daily_diff <- diff(log(Cl(stock_data))$Close)
stock_vol <- sqrt(252) * sd(daily_diff)
View(rates_data)
rates_data$exchangerates <- rates_data$`Euribor 3-month - Historical close, average of observations through period (FM.M.U2.EUR.RT.MM.EURIBOR3MD_.HSTA)`
# Convert balance sheet to Euro
balancesheet_data <- balancesheet_data %>%
mutate(across(where(is.numeric), ~.x * rates_data$exchangerates))
View(balancesheet_data)
colnames(balancesheet_data)
# Convert Date column to Date format
balancesheet_data$Date <- as.Date(balancesheet_data$X)
# Convert Date column to Date format
balancesheet_data$Date <- as.Date(balancesheet_data$...1)
balancesheet_data <- balancesheet_data %>%
select(Date, Total.Debt, Total.Assets)
balancesheet_data <- balancesheet_data %>%
select(Date, Total Debt, Total Assets)
balancesheet_data <- balancesheet_data %>%
select("Date", "Total Debt", "Total Assets")
# Convert balance sheet to Euro
balancesheet_data <- balancesheet_data %>%
mutate(across(where(is.numeric), ~.x * rates_data$exchangerates))
# Convert balance sheet to Euro
balancesheet_data <- balancesheet_data %>%
mutate(across(where(is.numeric), ~.Date * rates_data$exchangerates))
# Convert balance sheet to Euro
balancesheet_data <- balancesheet_data %>%
mutate(across(where(is.numeric), ~.x * rates_data$exchangerates))
View(rates_data)
rates_data$DATE <- as.Date(rates_data$DATE)
View(rates_data)
View(balancesheet_data)
colnames(rates_data)
rates_data <- rates_data %>%
select(DATE, exchangerates)
colnames(balancesheet_data)
colnames(rates_data)
bal_sheet <- merge(balancesheet_data, rates_data, by=c("Date", "DATE"))
bal_sheet <- merge(balancesheet_data, rates_data, by.x = c("Date"), by.y = c("DATE"))
View(bal_sheet)
balancesheet_data <- merge(balancesheet_data, rates_data, by.x = c("Date"), by.y = c("DATE"))
debt <- balancesheet_data$`Total Debt` * balancesheet_data$exchangerates
assets <- balancesheet_data$`Total Assets` * balancesheet_data$exchangerates
# Compute mean debt recovery rate
R <- 0.4
# Loop through each quarter
dt_defaults <- numeric(length(assets))
1:length(assets)
stock_vol[1]
stock_vol[2]
stock_vol[3]
stock_vol[4]
stock_vol[5]
view(stock_vol)
sd(daily_diff)
for(i in 1:length(assets)){
# Extract asset and debt values
A = assets[i]
D = debt[i]
# Compute leverage
L = D/A
# Extract volatility
sigma = stock_vol[i]
# Extract risk free rate
mu = rates_data[i,2]
# Calculate distance to default
dt_defaults[i] = (log(A/D) + (mu + 0.5*sigma^2)*1) / (sigma*sqrt(1))
}
# Take the average
dt_default <- mean(dt_defaults)
view(dt_defaults)
mean(dt_defaults)
dt_defaults
# Loop through each quarter
dt_defaults <- numeric(length(assets))
dt_defaults
for(i in 1:length(assets)){
# Extract asset and debt values
A = assets[i]
D = debt[i]
# Compute leverage
L = D/A
# Extract volatility
sigma = stock_vol[i]
# Extract risk free rate
mu = rates_data[i,2]
# Calculate distance to default
dt_defaults[i] = (log(A/D) + (mu + 0.5*sigma^2)*1) / (sigma*sqrt(1))
}
# Take the average
dt_default <- mean(dt_defaults)
View(dt_defaults)
view(stock_vol)
# Loop through each quarter
dt_defaults <- numeric(length(assets))
for(i in 1:length(assets)){
# Extract asset and debt values
A = assets[i]
D = debt[i]
# Compute leverage
L = D/A
# Extract risk free rate
mu = rates_data[i,2]
# Calculate distance to default
dt_defaults[i] = (log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))
}
View(dt_defaults)
# Take the average
dt_default <- mean(dt_defaults)
(log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))
(log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))[1]
typeof((log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1)))
(log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))[1]
typeof((log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))[1])
unlist((log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))[1])
unlist((log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))[1][1])
unlist((log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1)))
for(i in 1:length(assets)){
# Extract asset and debt values
A = assets[i]
D = debt[i]
# Compute leverage
L = D/A
# Extract risk free rate
mu = rates_data[i,2]
# Calculate distance to default
dt_defaults[i] = unlist((log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1)))
}
# Take the average
dt_default <- mean(dt_defaults)
View(dt_defaults)
[(log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))][1]
(log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))
(log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))[[1]]
unlist((log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1)))[1]
unlist((log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1)))[1]
unlist((log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1)))
xpm <- (log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))
xpm
xpm[[1]]
xpm[[1]][1]
unlist(xpm[[1]])
typeof(xpm[[1]])
for(i in 1:length(assets)){
# Extract asset and debt values
A = assets[i]
D = debt[i]
# Compute leverage
L = D/A
# Extract risk free rate
mu = rates_data[i,2]
# Calculate distance to default
xpm <- (log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))
dt_defaults[i] = xpm[[1]]
}
# Take the average
dt_default <- mean(dt_defaults)
View(dt_defaults)
xpm[[1]]
typeof(xpm[[1]])
vb <- 0.001
vb
# Loop through each quarter
dt_defaults <- numeric(length(assets))
for(i in 1:length(assets)){
# Extract asset and debt values
A = assets[i]
D = debt[i]
# Compute leverage
L = D/A
# Extract risk free rate
mu = rates_data[i,2]
# Calculate distance to default
xpm <- (log(A/D) + (mu + 0.5*stock_vol^2)*1) / (stock_vol*sqrt(1))
dt_defaults[i] = xpm[[1]]
}
# Take the average
dt_default <- mean(dt_defaults)
dt_default
# Map distance to default to probability of default
# Using normal CDF as no access to Moody's mapping
pd <- pnorm(dt_default)
View(rates_data)
view(assets)
mu
